# Product Requirements Document (PRD)

**Product:** MCP Security Gateway & Registry  
**Version:** v0.9‚Äëdraft  
**Authors:** Core Platform Team  
**LastUpdated:** 2025‚Äë08‚Äë04

> **üìç Navigation:** [Documentation Index](index.md) | [Implementation Plan](MCP_GATEWAY_IMPLEMENTATION.md) | [Feature Backlog](Backlog.md) | [Architecture Decisions](ARCHITECTURE_DECISIONS.md)

---

## 1Purpose & Vision

Building AI applications that invoke dozens of Model Context Protocol (MCP) tools across the enterprise today requires each client to juggle OAuth tokens, and each tool to implement its own authentication logic. **The MCP Security Gateway** centralises those concerns‚Äîacting as an identity‚Äëaware reverse proxy, dynamic registry, and policy enforcement point‚Äîso AI agents can safely discover and call only the tools they are authorised to use.

> **Vision:** ‚ÄúOne secure door‚Äù through which every AI assistant can reach enterprise tools without ever holding more privilege than its user.

---

## 2Background & Problem Statement

| Observed pain point                                                                     | Impact                                                                                    |
| --------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| Each MCP tool team re‚Äëimplements JWT validation and Azure AD integration.               | Duplicated effort, inconsistent security posture, audit overhead.                         |
| No central place to list available tools or gate them per user/role.                    | Users either see too many tools (confusing) or none at all; hard to meet least‚Äëprivilege. |
| Clients (ChatGPT, Claude Desktop) must manage refresh tokens and scopes for every tool. | Complex SDK logic, fragile token leakage risks.                                           |
| Regulators demand audit logs of who accessed which backend with which scope.            | Today logs are siloed across dozens of microservices.                                     |

---

## 3Goals / SuccessCriteria

| ID  | Goal                                        | Success Metric                                                                               |
| --- | ------------------------------------------- | -------------------------------------------------------------------------------------------- |
| G1 | Centralise token exchange via OAuth2.0 OBO | 100% of tool calls carry a gateway‚Äëissued TokenB; zero direct client‚Üítool calls by launch. |
| G2 | Tool discovery filtered by RBAC             | User sees ‚â§1 false‚Äëpositive tool per 1000 lookups (measured in UX tests).                  |
| G3 | <200ms P95 extra latency                  | Gateway overhead ‚â§200ms for streaming tools under 1000RPS.                               |
| G4 | Single‚Äëclick tool onboarding                | 90% of new tool registrations succeed on first attempt.                                     |
| G5 | Audit‚Äëready                                 | 100% of calls generate `ToolCalled` event with trace‚Äëid in SIEM.                            |

---

## 4Non‚ÄëGoals (v1)

* Graphical prompt‚Äëengineering UI.
* Automatic prompt‚Äësafety rewrites (planned post‚ÄëGA).
* Non‚ÄëHTTP transports (gRPC, AMQP).
* Cross‚Äëtenant marketplace distribution.

---

## 5Target Users & Personas

| Persona                | Needs                                                                   |
| ---------------------- | ----------------------------------------------------------------------- |
| **AI Application Dev** | Simple SDK to list and call tools without touching OAuth flows.         |
| **Tool Service Owner** | Drop‚Äëin manifest + JWT validation library; no custom gateway-side code. |
| **SecurityEngineer**  | Central policy engine; view audit logs; enforce mTLS & scopes.          |
| **PlatformAdmin**     | Register/retire tools; map AAD groups ‚Üí tool access.                    |

---

## 6User Stories (Prioritised)

1. **As an AI dev** I can obtain a single AAD token for the gateway and call any authorised tool so that I don‚Äôt manage dozens of scopes.
2. **As a tool owner** I POST a signed manifest and the tool instantly appears in QA with zero downtime.
3. **As an auditor** I query SIEM for ‚Äúwho called ToolX last week‚Äù and receive a full list with timestamps and user IDs.
4. **As a security engineer** I disable a compromised tool via the Admin UI and the gateway blocks calls within one second.
5. **As an external partner** (future) I can auth via my own AzureAD tenant without a separate account.

---

## 7Functional Requirements (FR)

| ID   | Requirement                                          | Priority    |
| ---- | ---------------------------------------------------- | ----------- |
| FR1 | Validate incoming JWT (`iss`, `aud`, `exp`, `azp`)   | MustHave   |
| FR2 | Perform OBO token exchange per `requiredScope`       | MustHave   |
| FR3 | Registry DB stores tool manifest incl. JSONSchema   | MustHave   |
| FR4 | `/tools` endpoint filters by user roles/groups claim | MustHave   |
| FR5 | Admin UI for CRUD on tools & RBAC matrix             | ShouldHave |
| FR6 | Streaming passthrough (SSE / HTTP‚ÄÜ2)                 | MustHave   |
| FR7 | Health probes & dynamic YARP reload                  | MustHave   |
| FR8 | Signed manifest onboarding with JOSE JWS             | ShouldHave |
| FR9 | Multi‚Äëtenant token validation (configurable)         | CouldHave  |

---

## 8Non‚ÄëFunctional Requirements (NFR)

* **Performance:** ‚â§200ms P95 overhead @1000RPS with 16KB payload.
* **Scalability:** Horizontal scale to 10K RPS (stateless; Redis token cache).
* **Security:** OWASPASVS Level2 compliance; TLS1.2+; mTLS optional.
* **Reliability:** 99.9% monthly gateway uptime; graceful drain on deploy.
* **Observability:** OpenTelemetry traces; Prometheus metrics; JSON logs.
* **Maintainability:** Configurable via DB without redeploy; IaC modules supplied.

---

## 9Assumptions

* All client apps can obtain AzureAD tokens (PublicClient flow).
* Each tool has or can implement JWT validation middleware.
* Redis and SQL/Cosmos are available as managed services in target deployments.

---

## 10Risks & Mitigations

| Risk                   | Likelihood | Impact | Mitigation                                                 |
| ---------------------- | ---------- | ------ | ---------------------------------------------------------- |
| Token cache corruption | Medium     | High   | Use Redis>=6 with AOF persistence and multi‚ÄëAZ.          |
| Tool manifest spoofing | Low        | High   | Require detachedJWS with tool‚Äôs cert; verify CN in AAD.   |
| Latency budget blow‚Äëup | Medium     | Medium | Perf test; introduce adaptive time‚Äëouts + circuit breaker. |
| Scope creep in v1      | High       | Medium | Enforce MoSCoW priorities; cut non‚Äëgoals.                  |

---

## 11MVP Scope

| Workstream   | MVP deliverable                                      |
| ------------ | ---------------------------------------------------- |
| CoreGateway | JWT validation, OBO token mediation, YARP proxy.     |
| Registry DB  | Tool manifest + RBAC tables; REST CRUD API.          |
| Admin UI     | Basic list/create/update tool; map AAD group ‚Üí tool. |
| SDK (.NET)   | Discovery + call helper with streaming.              |
| AzureDeploy | Terraform module; AppService + Redis + SQL.         |

Launch criteria = **GoalsG1‚ÄìG4** satisfied in staging + security review passed.

---

## 12Milestones & Timeline (tentative)

| Phase             | Dates            | Key outputs                                      |
| ----------------- | ---------------- | ------------------------------------------------ |
| Design freeze    | Aug18‚ÜíAug29 | Finalised manifests, DB schema, API spec         |
| MVPDev Sprint1 | Sep02‚ÜíSep27 | Core gateway, JWT validation, registry API       |
| Sprint2         | Sep30‚ÜíOct25 | OBO flow, Redis cache, .NET SDK alpha            |
| Sprint3         | Oct28‚ÜíNov22 | Admin UI beta, streaming passthrough, load tests |
| Beta release     | Dec02          | Pilot with Finance & HR tools                    |
| GA               | Jan152026     | Production rollout, SOC2 audit kickoff          |

---

## 13Metrics & KPIs

* **GatewayP95 latency** (ms)
* **Token cache hit‚Äërate** (%)
* **Tool registration successrate** (%)
* **Unauthorized access attempts blocked** (#/day)
* **Mean time to disable a tool** (seconds)

---

## 14Open Questions

1. Do we need gRPC support in 2026 roadmap?
2. Accept external IdPs (Okta) in MVP or post‚ÄëGA?
3. Which schema versioning strategy‚ÄîSemVer vs date‚Äëbased?
4. Who owns SOC2 evidence collection after GA?

---

*End of document*
